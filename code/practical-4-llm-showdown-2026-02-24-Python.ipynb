{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SGSSS Logo](../img/SGSSS_Stacked.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Digital Data for Social Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this session we evaluate how well LLMs can generate the code we wrote today. You will submit prompts to different LLMs (e.g., ChatGPT, Claude, an open model) and compare the quality of the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide to Using This Resource\n",
    "\n",
    "This notebook is designed to be used in Google Colab. To open it in Colab:\n",
    "\n",
    "1. Click on the **File** menu and select **Open in Colab**, or upload this `.ipynb` file directly to [Google Colab](https://colab.research.google.com/).\n",
    "2. You do not need to install anything locally -- Colab provides a free Python environment in your browser.\n",
    "3. Work through the cells in order, pasting LLM-generated code into the designated code cells.\n",
    "4. Use the markdown cells to record your evaluation notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Exercise\n",
    "\n",
    "In this practical you will:\n",
    "\n",
    "1. **Define coding prompts** based on the tasks we completed in today's practicals.\n",
    "2. **Submit each prompt** to at least three different LLMs (e.g., ChatGPT, Claude, and an open model such as Llama or Mistral).\n",
    "3. **Paste the generated code** into the cells below.\n",
    "4. **Evaluate the outputs** using a consistent set of criteria.\n",
    "\n",
    "The prompts below are already written for you. Your job is to submit them, collect the outputs, and assess the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Criteria\n",
    "\n",
    "Use the following criteria to evaluate each LLM's output:\n",
    "\n",
    "1. **Does the code run without errors?** -- Can you execute it in Colab without modifications?\n",
    "2. **Does it produce the correct output?** -- Does the result match what you would expect?\n",
    "3. **Does it use appropriate libraries?** -- Are the chosen packages standard and well-suited to the task?\n",
    "4. **Is the code well-structured and readable?** -- Is it clearly organised, with sensible variable names and comments?\n",
    "5. **Are there any security or ethical issues?** -- Does the code handle sensitive data appropriately? Does it respect rate limits and terms of service?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 1: Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the following prompt to each LLM:\n",
    "\n",
    "> Write a Python script that scrapes all organisation names and URLs from the Edinburgh Council warm and welcoming spaces directory (https://www.edinburgh.gov.uk/directory/10258/other-warm-and-welcoming-locations). The script should loop through the A-Z pages, extract each organisation's name and link, and save the results as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste ChatGPT output here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste Claude output here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste open model output here (e.g., Llama, Mistral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "| Criterion | ChatGPT | Claude | Open Model |\n",
    "|---|---|---|---|\n",
    "| Runs without errors? | | | |\n",
    "| Correct output? | | | |\n",
    "| Appropriate libraries? | | | |\n",
    "| Well-structured? | | | |\n",
    "| Security/ethical issues? | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 2: API Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the following prompt to each LLM:\n",
    "\n",
    "> Write a Python script that downloads stop-and-search data for all police forces using the UK Police API (https://data.police.uk/api/). The script should get a list of forces, loop through each one to request stop-and-search data, handle errors, respect rate limits, and save all results as a single JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste ChatGPT output here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste Claude output here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste open model output here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "| Criterion | ChatGPT | Claude | Open Model |\n",
    "|---|---|---|---|\n",
    "| Runs without errors? | | | |\n",
    "| Correct output? | | | |\n",
    "| Appropriate libraries? | | | |\n",
    "| Well-structured? | | | |\n",
    "| Security/ethical issues? | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 3: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the following prompt to each LLM:\n",
    "\n",
    "> Write a Python script that requests GDP data for all G7 countries from the World Bank API (https://api.worldbank.org/v2/), converts the results to a pandas DataFrame, and creates a bar chart comparing the most recent GDP figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste ChatGPT output here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste Claude output here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste open model output here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "| Criterion | ChatGPT | Claude | Open Model |\n",
    "|---|---|---|---|\n",
    "| Runs without errors? | | | |\n",
    "| Correct output? | | | |\n",
    "| Appropriate libraries? | | | |\n",
    "| Well-structured? | | | |\n",
    "| Security/ethical issues? | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on the following questions with your group:\n",
    "\n",
    "1. Which LLM produced the best code overall? What made it better?\n",
    "2. Did any LLM produce code that looked correct but was actually wrong? How would you know?\n",
    "3. What information did you need to include in your prompt to get good results?\n",
    "4. How would you use LLMs in your own research workflow? Where would you trust them and where would you not?\n",
    "5. What are the implications for reproducibility if researchers use LLM-generated code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Solutions\n",
    "\n",
    "Compare the LLM outputs against the code in Practicals 1-3. Those notebooks represent tested, working solutions that we built step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**END OF FILE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}